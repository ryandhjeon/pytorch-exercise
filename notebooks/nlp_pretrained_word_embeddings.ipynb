{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using IMDB review data as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.legacy import data, datasets\n",
    "from gensim.models import KeyedVectors\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
    "LABEL = data.Field(sequential=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:21<00:00, 3.93MB/s]\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data : 25000\n"
     ]
    }
   ],
   "source": [
    "print('Size of training data : {}' .format(len(trainset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['for', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem.', 'imagine', 'a', 'movie', 'where', 'joe', 'piscopo', 'is', 'actually', 'funny!', 'maureen', 'stapleton', 'is', 'a', 'scene', 'stealer.', 'the', 'moroni', 'character', 'is', 'an', 'absolute', 'scream.', 'watch', 'for', 'alan', '\"the', 'skipper\"', 'hale', 'jr.', 'as', 'a', 'police', 'sgt.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(trainset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking pretrained Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format('../dataset/punkt/eng_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.41237423 -0.40173793 -0.19030268 -0.47487482  0.17101552  1.9634222\n",
      " -0.9386157  -0.2541767  -0.17827566  1.5681139  -0.21593682  1.6120319\n",
      " -1.2547855  -0.38687736 -0.27799815  1.2774913   0.8133057  -0.5084944\n",
      "  0.25357205 -1.6029936   0.528238    0.7256684   0.94486576 -0.70858157\n",
      "  0.4912014  -2.3105843  -1.7756648   0.46488804  0.03967098 -0.1323693\n",
      "  1.3075948   0.2960277   0.9070871  -1.9766766   0.1978702  -1.1319329\n",
      " -1.3083407  -0.26808804  1.6706523  -2.1393409  -0.3959836  -0.72865075\n",
      " -1.8998241  -0.43317813 -0.504071   -1.5388873  -0.94332737  1.3004092\n",
      " -0.07406762 -1.4345086   0.30321598  0.30422762 -1.8357753   0.28988233\n",
      " -0.33083802 -1.9591426  -1.035728    0.02213317 -0.7617007   0.54199463\n",
      " -0.8089983  -0.6452749   1.6342394   0.41099605 -0.38492674 -0.73069537\n",
      " -0.7576174   1.0925194  -0.75652033  0.20524448 -0.30603978  1.268685\n",
      " -2.9661946   1.363108    1.5051506   0.0954047   0.21077555 -0.66317445\n",
      "  0.41726002 -1.563157   -0.62894857 -0.529535    1.5583583   0.6484077\n",
      " -0.06629205 -2.4497204  -1.542017   -0.54917175 -2.449053    0.19258618\n",
      " -0.8674844   1.6830556   0.14685324  0.2516902   1.4264681  -1.2276392\n",
      "  0.03419128  0.3147852  -0.04810404  0.74804145]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model['this'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'self-indulgent' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f37394b7be3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'self-indulgent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \"\"\"\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \"\"\"\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'self-indulgent' not present\""
     ]
    }
   ],
   "source": [
    "print(word2vec_model['self-indulgent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21613 [00:00<?, ?it/s]WARNING:torchtext.vocab:Skipping token b'21613' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████| 21613/21613 [00:02<00:00, 9609.78it/s] \n"
     ]
    }
   ],
   "source": [
    "vectors = Vectors(name=\"../dataset/punkt/eng_w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trainset, vectors=vectors, max_size=10000, min_freq=10) # Word2Vec 모델을 임베딩 벡터값으로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of embedding vector, dimension : torch.Size([10002, 100]) \n"
     ]
    }
   ],
   "source": [
    "print('# of embedding vector, dimension : {} '.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors[0]) # Embedding vector of <unk>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors[1]) # Embedding vector of <pad>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4124, -0.4017, -0.1903, -0.4749,  0.1710,  1.9634, -0.9386, -0.2542,\n",
      "        -0.1783,  1.5681, -0.2159,  1.6120, -1.2548, -0.3869, -0.2780,  1.2775,\n",
      "         0.8133, -0.5085,  0.2536, -1.6030,  0.5282,  0.7257,  0.9449, -0.7086,\n",
      "         0.4912, -2.3106, -1.7757,  0.4649,  0.0397, -0.1324,  1.3076,  0.2960,\n",
      "         0.9071, -1.9767,  0.1979, -1.1319, -1.3083, -0.2681,  1.6707, -2.1393,\n",
      "        -0.3960, -0.7287, -1.8998, -0.4332, -0.5041, -1.5389, -0.9433,  1.3004,\n",
      "        -0.0741, -1.4345,  0.3032,  0.3042, -1.8358,  0.2899, -0.3308, -1.9591,\n",
      "        -1.0357,  0.0221, -0.7617,  0.5420, -0.8090, -0.6453,  1.6342,  0.4110,\n",
      "        -0.3849, -0.7307, -0.7576,  1.0925, -0.7565,  0.2052, -0.3060,  1.2687,\n",
      "        -2.9662,  1.3631,  1.5052,  0.0954,  0.2108, -0.6632,  0.4173, -1.5632,\n",
      "        -0.6289, -0.5295,  1.5584,  0.6484, -0.0663, -2.4497, -1.5420, -0.5492,\n",
      "        -2.4491,  0.1926, -0.8675,  1.6831,  0.1469,  0.2517,  1.4265, -1.2276,\n",
      "         0.0342,  0.3148, -0.0481,  0.7480])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors[10]) # Embedding vector of <this>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors[10000]) # Embedding vector of <self-indulgent>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding.from_pretrained(TEXT.vocab.vectors, freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4124, -0.4017, -0.1903, -0.4749,  0.1710,  1.9634, -0.9386, -0.2542,\n",
      "         -0.1783,  1.5681, -0.2159,  1.6120, -1.2548, -0.3869, -0.2780,  1.2775,\n",
      "          0.8133, -0.5085,  0.2536, -1.6030,  0.5282,  0.7257,  0.9449, -0.7086,\n",
      "          0.4912, -2.3106, -1.7757,  0.4649,  0.0397, -0.1324,  1.3076,  0.2960,\n",
      "          0.9071, -1.9767,  0.1979, -1.1319, -1.3083, -0.2681,  1.6707, -2.1393,\n",
      "         -0.3960, -0.7287, -1.8998, -0.4332, -0.5041, -1.5389, -0.9433,  1.3004,\n",
      "         -0.0741, -1.4345,  0.3032,  0.3042, -1.8358,  0.2899, -0.3308, -1.9591,\n",
      "         -1.0357,  0.0221, -0.7617,  0.5420, -0.8090, -0.6453,  1.6342,  0.4110,\n",
      "         -0.3849, -0.7307, -0.7576,  1.0925, -0.7565,  0.2052, -0.3060,  1.2687,\n",
      "         -2.9662,  1.3631,  1.5052,  0.0954,  0.2108, -0.6632,  0.4173, -1.5632,\n",
      "         -0.6289, -0.5295,  1.5584,  0.6484, -0.0663, -2.4497, -1.5420, -0.5492,\n",
      "         -2.4491,  0.1926, -0.8675,  1.6831,  0.1469,  0.2517,  1.4265, -1.2276,\n",
      "          0.0342,  0.3148, -0.0481,  0.7480]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.LongTensor([10]))) # Embedding vector of <this>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained from torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [03:35, 3.99MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [01:22<00:00, 4819.93it/s]\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(trainset, vectors=GloVe(name='6B', dim=300), max_size=10000, min_freq=10)\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of embedding vector, dimension : torch.Size([10002, 300]) \n"
     ]
    }
   ],
   "source": [
    "print('# of embedding vector, dimension : {} '.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors[0]) # Embedding vector of <unk>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors[1]) # Embedding vector of <pad>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0437e-01,  1.6431e-01,  4.1794e-02, -1.3708e-01, -2.9779e-01,\n",
      "         3.3440e-01, -6.9955e-02, -6.8036e-02,  1.0604e-01, -2.0337e+00,\n",
      "         1.7977e-01, -7.7403e-02, -1.9518e-01,  1.8324e-01,  3.0017e-02,\n",
      "        -5.4762e-02, -4.5725e-01, -2.4509e-02,  5.7387e-02, -3.4878e-01,\n",
      "         3.9696e-02,  4.4826e-01, -5.8462e-02,  4.1181e-01, -3.5411e-02,\n",
      "        -1.4722e-01,  1.0740e-01, -2.5896e-01, -1.1658e-01,  1.9822e-01,\n",
      "         3.2850e-01,  2.4177e-01, -5.7177e-01, -5.6442e-02, -9.6437e-01,\n",
      "         3.4482e-01,  5.4639e-02,  2.3828e-01, -1.9139e-01,  3.0899e-01,\n",
      "         2.8044e-01, -3.3814e-02, -2.5436e-01,  1.5373e-02,  1.6341e-01,\n",
      "         2.6352e-01,  1.5812e-01,  3.2044e-01, -2.3082e-01,  2.6050e-01,\n",
      "         2.0606e-01, -8.9769e-02, -1.0055e-01,  7.0378e-02, -2.7452e-02,\n",
      "         2.7959e-01, -9.5862e-02,  2.0574e-01,  2.9522e-01, -1.2285e-02,\n",
      "         1.1164e-01, -5.1373e-02,  4.6106e-01,  2.3014e-02, -3.7141e-01,\n",
      "        -2.4166e-01,  3.3773e-02,  3.6827e-02,  1.6918e-01, -1.0802e-01,\n",
      "        -1.0691e-01,  1.0219e-01,  1.0065e-01,  5.5907e-02, -2.7402e-01,\n",
      "        -1.3689e-01,  4.2095e-01, -2.4060e-02, -3.2099e-01,  3.2065e-01,\n",
      "        -1.6776e-01,  1.0170e-01,  7.4999e-02, -1.0486e-01,  3.7114e-01,\n",
      "         3.2972e-01, -3.3043e-01,  3.8343e-01,  2.4555e-01,  2.0386e-01,\n",
      "        -4.1919e-01,  1.1570e-01, -7.8632e-02, -4.3171e-01, -2.3550e-02,\n",
      "        -1.1618e-01, -2.5605e-01,  3.4693e-01,  2.0398e-01, -1.7857e-01,\n",
      "         1.7301e-01,  4.6408e-02, -1.0486e-01,  9.8706e-02, -3.2077e-02,\n",
      "        -3.0462e-01,  1.2826e-01,  6.7985e-02, -2.5993e-01,  3.8041e-01,\n",
      "         4.5252e-02, -9.1834e-02, -4.5206e-01, -1.2498e-01,  1.7515e-01,\n",
      "        -1.3551e-01, -2.0556e-03, -9.3906e-02, -2.8006e-02, -4.6975e-01,\n",
      "         8.4430e-03, -2.4092e-01,  1.6000e-01,  2.2063e-01,  3.6277e-01,\n",
      "        -6.7643e-02,  2.8755e-01,  1.2643e-01,  1.2202e-01,  1.0548e-01,\n",
      "         4.0249e-01,  2.9781e-01,  4.9507e-01, -1.1096e-01, -2.4472e-01,\n",
      "         1.8720e-01,  1.1156e-01,  1.5680e-02,  7.6296e-03,  1.4304e-01,\n",
      "        -2.9299e-01,  1.7912e-01,  1.1604e-02, -5.6776e-02, -5.0224e-01,\n",
      "        -4.7262e-01,  1.5790e-01,  3.1573e-01, -7.7839e-02,  3.5172e-01,\n",
      "         1.6097e-01, -2.2595e-01,  2.4629e-01, -3.8200e-02,  6.4918e-01,\n",
      "         5.9545e-02, -5.0641e-02,  1.9511e-01, -6.8791e-02, -1.5146e-01,\n",
      "         1.2101e-02, -4.5943e-01,  1.4300e-02, -8.7461e-02, -3.2711e-02,\n",
      "         2.4036e-01,  1.7293e-02,  1.1340e-01, -3.4248e-02,  5.0351e-02,\n",
      "         9.3530e-02, -6.4975e-02, -8.5025e-01, -1.3809e-01, -3.4919e-01,\n",
      "        -2.0540e-02, -3.7268e-01,  4.7773e-02,  4.7216e-02,  2.3236e-01,\n",
      "         1.3777e-01,  2.4962e-01,  1.3133e-01,  4.7732e-02,  4.4829e-02,\n",
      "        -1.3243e-01, -1.6702e-01,  2.1045e-01, -4.0940e-02,  3.1555e-01,\n",
      "        -5.1593e-01,  1.0297e-01,  2.9704e-01,  1.6769e-02, -2.1701e-02,\n",
      "         5.7481e-03,  6.0955e-02, -2.2314e-02,  1.6080e-01, -2.1614e-01,\n",
      "         1.0959e+00, -4.0587e-01, -1.4514e-01, -1.3610e-01,  1.1280e-01,\n",
      "         1.7697e-01, -6.5900e-02, -1.3467e-01, -5.1049e-02, -2.8790e-01,\n",
      "        -3.9537e-01,  7.9347e-02,  5.7817e-01, -1.2027e-02, -1.2462e-01,\n",
      "         4.0711e-02,  1.3596e-02,  2.0398e-01,  9.5604e-02,  6.8153e-03,\n",
      "         2.5994e-01, -1.0152e-01, -3.8128e-01,  4.2629e-01,  1.8734e-01,\n",
      "         7.3060e-03,  6.0062e-01,  2.1663e-01,  2.3836e-02,  1.2912e-02,\n",
      "        -3.0333e-01,  3.1381e-01, -2.6096e-02, -3.8907e-01,  5.5081e-02,\n",
      "        -5.0901e-02,  2.5939e-01, -2.6417e-01,  2.0716e-01,  2.2498e-01,\n",
      "         1.9117e-01,  1.2614e-01,  1.4713e-01,  1.0489e-01, -1.1291e+00,\n",
      "        -8.1722e-02,  1.2693e-01,  1.5365e-01, -8.2781e-02, -3.5168e-01,\n",
      "         1.7873e-01, -9.7911e-02, -2.5831e-01,  9.0010e-03,  3.9271e-01,\n",
      "         9.9305e-02,  2.0227e-02,  9.2149e-03,  3.3352e-01, -7.1636e-02,\n",
      "        -5.9093e-02,  9.9506e-02,  3.1135e-01,  3.1324e-01, -1.0208e-01,\n",
      "        -6.0717e-02, -4.3183e-02, -8.3102e-02,  5.3218e-01, -1.6997e-01,\n",
      "         1.1647e-01, -1.0793e-01, -3.3692e-02,  1.6272e-01,  2.0517e-01,\n",
      "         1.1426e-01, -2.0803e+00, -4.4386e-03,  8.7898e-01,  4.7096e-01,\n",
      "        -2.7657e-01, -1.9387e-01, -9.8869e-02, -1.1244e-01, -1.4206e-01,\n",
      "         9.0613e-02, -1.8396e-01,  3.6844e-02, -1.9090e-01,  8.6006e-02,\n",
      "         9.2397e-04, -4.1547e-01, -7.7672e-02,  5.0569e-01,  2.4725e-01,\n",
      "         2.4119e-01, -1.3455e-01, -3.4007e-01, -7.7146e-02, -8.4089e-02])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors[10]) # Embedding vector of <this>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.vectors[9999]) # Embedding vector of <seeing>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TEXT.vocab.vectors as nn.Embedding() initial value\n",
    "embedding_layer = nn.Embedding.from_pretrained(TEXT.vocab.vectors, freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0437e-01,  1.6431e-01,  4.1794e-02, -1.3708e-01, -2.9779e-01,\n",
       "          3.3440e-01, -6.9955e-02, -6.8036e-02,  1.0604e-01, -2.0337e+00,\n",
       "          1.7977e-01, -7.7403e-02, -1.9518e-01,  1.8324e-01,  3.0017e-02,\n",
       "         -5.4762e-02, -4.5725e-01, -2.4509e-02,  5.7387e-02, -3.4878e-01,\n",
       "          3.9696e-02,  4.4826e-01, -5.8462e-02,  4.1181e-01, -3.5411e-02,\n",
       "         -1.4722e-01,  1.0740e-01, -2.5896e-01, -1.1658e-01,  1.9822e-01,\n",
       "          3.2850e-01,  2.4177e-01, -5.7177e-01, -5.6442e-02, -9.6437e-01,\n",
       "          3.4482e-01,  5.4639e-02,  2.3828e-01, -1.9139e-01,  3.0899e-01,\n",
       "          2.8044e-01, -3.3814e-02, -2.5436e-01,  1.5373e-02,  1.6341e-01,\n",
       "          2.6352e-01,  1.5812e-01,  3.2044e-01, -2.3082e-01,  2.6050e-01,\n",
       "          2.0606e-01, -8.9769e-02, -1.0055e-01,  7.0378e-02, -2.7452e-02,\n",
       "          2.7959e-01, -9.5862e-02,  2.0574e-01,  2.9522e-01, -1.2285e-02,\n",
       "          1.1164e-01, -5.1373e-02,  4.6106e-01,  2.3014e-02, -3.7141e-01,\n",
       "         -2.4166e-01,  3.3773e-02,  3.6827e-02,  1.6918e-01, -1.0802e-01,\n",
       "         -1.0691e-01,  1.0219e-01,  1.0065e-01,  5.5907e-02, -2.7402e-01,\n",
       "         -1.3689e-01,  4.2095e-01, -2.4060e-02, -3.2099e-01,  3.2065e-01,\n",
       "         -1.6776e-01,  1.0170e-01,  7.4999e-02, -1.0486e-01,  3.7114e-01,\n",
       "          3.2972e-01, -3.3043e-01,  3.8343e-01,  2.4555e-01,  2.0386e-01,\n",
       "         -4.1919e-01,  1.1570e-01, -7.8632e-02, -4.3171e-01, -2.3550e-02,\n",
       "         -1.1618e-01, -2.5605e-01,  3.4693e-01,  2.0398e-01, -1.7857e-01,\n",
       "          1.7301e-01,  4.6408e-02, -1.0486e-01,  9.8706e-02, -3.2077e-02,\n",
       "         -3.0462e-01,  1.2826e-01,  6.7985e-02, -2.5993e-01,  3.8041e-01,\n",
       "          4.5252e-02, -9.1834e-02, -4.5206e-01, -1.2498e-01,  1.7515e-01,\n",
       "         -1.3551e-01, -2.0556e-03, -9.3906e-02, -2.8006e-02, -4.6975e-01,\n",
       "          8.4430e-03, -2.4092e-01,  1.6000e-01,  2.2063e-01,  3.6277e-01,\n",
       "         -6.7643e-02,  2.8755e-01,  1.2643e-01,  1.2202e-01,  1.0548e-01,\n",
       "          4.0249e-01,  2.9781e-01,  4.9507e-01, -1.1096e-01, -2.4472e-01,\n",
       "          1.8720e-01,  1.1156e-01,  1.5680e-02,  7.6296e-03,  1.4304e-01,\n",
       "         -2.9299e-01,  1.7912e-01,  1.1604e-02, -5.6776e-02, -5.0224e-01,\n",
       "         -4.7262e-01,  1.5790e-01,  3.1573e-01, -7.7839e-02,  3.5172e-01,\n",
       "          1.6097e-01, -2.2595e-01,  2.4629e-01, -3.8200e-02,  6.4918e-01,\n",
       "          5.9545e-02, -5.0641e-02,  1.9511e-01, -6.8791e-02, -1.5146e-01,\n",
       "          1.2101e-02, -4.5943e-01,  1.4300e-02, -8.7461e-02, -3.2711e-02,\n",
       "          2.4036e-01,  1.7293e-02,  1.1340e-01, -3.4248e-02,  5.0351e-02,\n",
       "          9.3530e-02, -6.4975e-02, -8.5025e-01, -1.3809e-01, -3.4919e-01,\n",
       "         -2.0540e-02, -3.7268e-01,  4.7773e-02,  4.7216e-02,  2.3236e-01,\n",
       "          1.3777e-01,  2.4962e-01,  1.3133e-01,  4.7732e-02,  4.4829e-02,\n",
       "         -1.3243e-01, -1.6702e-01,  2.1045e-01, -4.0940e-02,  3.1555e-01,\n",
       "         -5.1593e-01,  1.0297e-01,  2.9704e-01,  1.6769e-02, -2.1701e-02,\n",
       "          5.7481e-03,  6.0955e-02, -2.2314e-02,  1.6080e-01, -2.1614e-01,\n",
       "          1.0959e+00, -4.0587e-01, -1.4514e-01, -1.3610e-01,  1.1280e-01,\n",
       "          1.7697e-01, -6.5900e-02, -1.3467e-01, -5.1049e-02, -2.8790e-01,\n",
       "         -3.9537e-01,  7.9347e-02,  5.7817e-01, -1.2027e-02, -1.2462e-01,\n",
       "          4.0711e-02,  1.3596e-02,  2.0398e-01,  9.5604e-02,  6.8153e-03,\n",
       "          2.5994e-01, -1.0152e-01, -3.8128e-01,  4.2629e-01,  1.8734e-01,\n",
       "          7.3060e-03,  6.0062e-01,  2.1663e-01,  2.3836e-02,  1.2912e-02,\n",
       "         -3.0333e-01,  3.1381e-01, -2.6096e-02, -3.8907e-01,  5.5081e-02,\n",
       "         -5.0901e-02,  2.5939e-01, -2.6417e-01,  2.0716e-01,  2.2498e-01,\n",
       "          1.9117e-01,  1.2614e-01,  1.4713e-01,  1.0489e-01, -1.1291e+00,\n",
       "         -8.1722e-02,  1.2693e-01,  1.5365e-01, -8.2781e-02, -3.5168e-01,\n",
       "          1.7873e-01, -9.7911e-02, -2.5831e-01,  9.0010e-03,  3.9271e-01,\n",
       "          9.9305e-02,  2.0227e-02,  9.2149e-03,  3.3352e-01, -7.1636e-02,\n",
       "         -5.9093e-02,  9.9506e-02,  3.1135e-01,  3.1324e-01, -1.0208e-01,\n",
       "         -6.0717e-02, -4.3183e-02, -8.3102e-02,  5.3218e-01, -1.6997e-01,\n",
       "          1.1647e-01, -1.0793e-01, -3.3692e-02,  1.6272e-01,  2.0517e-01,\n",
       "          1.1426e-01, -2.0803e+00, -4.4386e-03,  8.7898e-01,  4.7096e-01,\n",
       "         -2.7657e-01, -1.9387e-01, -9.8869e-02, -1.1244e-01, -1.4206e-01,\n",
       "          9.0613e-02, -1.8396e-01,  3.6844e-02, -1.9090e-01,  8.6006e-02,\n",
       "          9.2397e-04, -4.1547e-01, -7.7672e-02,  5.0569e-01,  2.4725e-01,\n",
       "          2.4119e-01, -1.3455e-01, -3.4007e-01, -7.7146e-02, -8.4089e-02]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(torch.LongTensor([10])) # Embedding vector of <this>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
